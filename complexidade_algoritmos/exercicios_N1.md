# üß† Question√°rio ‚Äî Complexidade de Algoritmos

---

## üìò Vers√£o F√°cil

**Objetivo:** Avaliar a compreens√£o dos conceitos b√°sicos de complexidade de algoritmos, nota√ß√µes e exemplos simples.

1. O que significa a palavra **complexidade** quando falamos de um algoritmo?  
2. Qual √© a diferen√ßa entre **tempo de execu√ß√£o** e **uso de mem√≥ria** em um algoritmo?  
3. Para que serve a **nota√ß√£o Big O (O-grande)**?  
4. O que representa o termo **n** dentro da nota√ß√£o O(n)?  
5. Cite um exemplo de algoritmo com complexidade **O(1)**.  
6. Cite um exemplo de algoritmo com complexidade **O(n)**.  
7. Qual a complexidade de tempo do algoritmo de **Bubble Sort**?  
8. Qual a complexidade de tempo do algoritmo de **Busca Linear**?  
9. O que significa dizer que um algoritmo tem complexidade **O(log n)**?  
10. Qual a diferen√ßa entre **melhor caso** e **pior caso** de um algoritmo?  
11. Em qual tipo de problema geralmente encontramos complexidades **exponenciais (O(2‚Åø))**?  
12. O que √© **complexidade polinomial**?  
13. Qual a complexidade do **Merge Sort** no pior caso?  
14. Em um algoritmo que possui **dois loops for aninhados**, qual costuma ser sua complexidade?  
15. Por que os programadores buscam algoritmos com menor complexidade?  
16. Um algoritmo que analisa cada elemento de uma lista apenas uma vez √© O(n). Isso √© considerado eficiente?  
17. A nota√ß√£o **Œò (teta)** indica o qu√™ em rela√ß√£o ao crescimento da fun√ß√£o?  
18. Qual √© a complexidade de tempo de um algoritmo que executa **tr√™s loops aninhados** sobre *n* elementos?  
19. O que significa dizer que um algoritmo √© **in-place**?  
20. Cite um exemplo de **estrutura de dados** que pode melhorar a efici√™ncia de um algoritmo.

---

## üî¨ Vers√£o Dif√≠cil

**Objetivo:** Avaliar a aplica√ß√£o pr√°tica e an√°lise cr√≠tica de complexidades, rela√ß√µes de recorr√™ncia e otimiza√ß√£o.

1. Explique por que analisamos a complexidade de tempo **em fun√ß√£o do tamanho da entrada (n)**.  
2. D√™ um exemplo de algoritmo cuja complexidade muda dependendo da escolha da estrutura de dados.  
3. Mostre como se calcula a complexidade assint√≥tica da fun√ß√£o **f(n) = 4n¬≤ + 3n + 10**.  
4. Prove que **O(n¬≤ + n) = O(n¬≤)**.  
5. Qual √© a diferen√ßa entre as nota√ß√µes **O(n)** e **Œ©(n)** em termos de limites de crescimento?  
6. Escreva a rela√ß√£o de recorr√™ncia do algoritmo **Merge Sort** e resolva-a usando o **Teorema Mestre**.  
7. Mostre um exemplo de algoritmo cuja complexidade √© **O(n log n)** e explique por que esse comportamento ocorre.  
8. Explique o que significa o **custo amortizado** em opera√ß√µes de uma **tabela hash**.  
9. Dado um algoritmo com complexidade **T(n) = 2T(n/2) + n**, determine sua ordem de crescimento.  
10. Compare o desempenho de algoritmos com complexidade **O(n log n)** e **O(n¬≤)** para valores grandes de *n*.  
11. Um algoritmo recursivo √© definido por **T(n) = T(n-1) + n**. Qual √© sua complexidade aproximada?  
12. Qual o impacto da escolha de piv√¥ na complexidade m√©dia do **Quick Sort**?  
13. Explique o conceito de **limite inferior (lower bound)** para algoritmos de ordena√ß√£o.  
14. D√™ um exemplo de problema **NP-dif√≠cil** e explique o que isso significa em termos de complexidade.  
15. Por que n√£o √© poss√≠vel encontrar algoritmos polinomiais conhecidos para resolver todos os problemas **NP-completos**?  
16. Mostre um exemplo pr√°tico em que a an√°lise de complexidade **pode orientar o design de software**.  
17. Explique a diferen√ßa entre **complexidade no caso m√©dio** e **complexidade no pior caso**.  
18. Um algoritmo que compara todos os pares de elementos em uma lista de tamanho *n* possui qual complexidade?  
19. Mostre por que **f(n) = n!** cresce mais rapidamente do que **f(n) = 2‚Åø**.  
20. Se um algoritmo tem tempo de execu√ß√£o **T(n) = n¬≤ log n + 5n**, qual √© sua complexidade em nota√ß√£o O?

---
# üß† Gabarito ‚Äî Complexidade de Algoritmos

---

## üìò Vers√£o F√°cil

1. **Complexidade** mede o quanto um algoritmo consome de **tempo** e/ou **mem√≥ria** conforme o tamanho da entrada aumenta.  
2. **Tempo de execu√ß√£o** √© quanto o algoritmo demora para terminar; **uso de mem√≥ria** √© o quanto de espa√ßo ele ocupa durante a execu√ß√£o.  
3. A **nota√ß√£o Big O** descreve o **comportamento assint√≥tico**, ou seja, como o tempo de execu√ß√£o cresce em rela√ß√£o ao tamanho da entrada.  
4. O termo **n** representa o **tamanho da entrada** (ex: n√∫mero de elementos em uma lista).  
5. Exemplo de **O(1)**: acesso direto a um elemento de um vetor (`array[i]`).  
6. Exemplo de **O(n)**: percorrer todos os elementos de uma lista (busca linear).  
7. **Bubble Sort** tem complexidade **O(n¬≤)**.  
8. **Busca Linear** tamb√©m √© **O(n)**.  
9. **O(log n)** indica que o tempo cresce lentamente ‚Äî t√≠pico de algoritmos que **dividem o problema pela metade**, como a **busca bin√°ria**.  
10. **Melhor caso:** execu√ß√£o mais r√°pida poss√≠vel; **pior caso:** execu√ß√£o mais lenta poss√≠vel.  
11. Complexidades **exponenciais (O(2‚Åø))** aparecem em problemas de **for√ßa bruta** ou **combinat√≥rios**, como o *caixeiro-viajante*.  
12. **Complexidade polinomial** √© quando o tempo cresce como uma pot√™ncia de *n* (ex: n¬≤, n¬≥).  
13. **Merge Sort** no pior caso tem **O(n log n)**.  
14. Dois **loops aninhados** ‚Üí **O(n¬≤)**.  
15. Porque algoritmos mais eficientes **economizam tempo e recursos**, especialmente em entradas grandes.  
16. Sim, **O(n)** √© considerado **eficiente**, pois cresce linearmente.  
17. A nota√ß√£o **Œò (teta)** indica o **crescimento exato** da fun√ß√£o ‚Äî tanto limite superior quanto inferior.  
18. Tr√™s loops aninhados ‚Üí **O(n¬≥)**.  
19. Um algoritmo **in-place** n√£o usa mem√≥ria extra significativa (ex: ordena√ß√£o feita no pr√≥prio vetor).  
20. Estruturas como **√°rvores balanceadas**, **tabelas hash** e **heaps** aumentam a efici√™ncia de busca e ordena√ß√£o.

---

## üî¨ Vers√£o Dif√≠cil

1. Porque o **tamanho da entrada (n)** afeta diretamente o n√∫mero de opera√ß√µes e o desempenho do algoritmo.  
2. Exemplo: **busca de elemento** ‚Äî em uma **lista** √© O(n), mas em uma **tabela hash** √© O(1).  
3. **f(n) = 4n¬≤ + 3n + 10 ‚Üí O(n¬≤)**, pois o termo de maior grau domina o crescimento.  
4. Como **n¬≤** cresce mais r√°pido que **n**, o termo **n** √© desprez√°vel ‚Äî logo, O(n¬≤ + n) = O(n¬≤).  
5. **O(n)** √© o limite superior (pior caso), **Œ©(n)** √© o limite inferior (melhor caso).  
6. Rela√ß√£o: **T(n) = 2T(n/2) + n** ‚Üí pelo **Teorema Mestre**, temos **O(n log n)**.  
7. Exemplo: **Merge Sort** ou **Quick Sort (caso m√©dio)** ‚Äî ocorre porque o problema √© dividido em partes menores e os resultados s√£o combinados.  
8. **Custo amortizado** √© o custo m√©dio por opera√ß√£o ap√≥s v√°rias execu√ß√µes ‚Äî usado em **estruturas din√¢micas** como **vetores redimension√°veis** e **tabelas hash**.  
9. **T(n) = 2T(n/2) + n ‚Üí O(n log n)** (mesmo resultado do Merge Sort).  
10. Para valores grandes de *n*, **O(n log n)** cresce muito mais lentamente que **O(n¬≤)** ‚Äî logo, √© mais eficiente.  
11. **T(n) = T(n-1) + n ‚Üí O(n¬≤)** (soma aritm√©tica de 1 a n).  
12. A escolha ruim do piv√¥ pode gerar parti√ß√µes desbalanceadas, elevando o Quick Sort de **O(n log n)** para **O(n¬≤)**.  
13. O **limite inferior** define o menor tempo te√≥rico poss√≠vel ‚Äî por exemplo, **O(n log n)** √© o limite inferior para algoritmos de ordena√ß√£o por compara√ß√£o.  
14. Exemplo: **Problema do Caixeiro-Viajante (TSP)** ‚Äî NP-dif√≠cil significa que **n√£o h√° algoritmo polinomial conhecido** e que resolver o problema √© t√£o dif√≠cil quanto os mais dif√≠ceis da classe NP.  
15. Porque **ningu√©m encontrou (nem provou existir)** um algoritmo polinomial para todos os problemas NP-completos; √© a base do **Problema P vs NP**.  
16. Exemplo: escolher **√°rvores balanceadas (O(log n))** em vez de **listas (O(n))** para buscas r√°pidas em um sistema de cadastro.  
17. **Caso m√©dio:** comportamento t√≠pico; **pior caso:** execu√ß√£o mais demorada poss√≠vel.  
18. Comparar todos os pares ‚Üí **O(n¬≤)**.  
19. **n!** cresce mais r√°pido porque **multiplica por n√∫meros cada vez maiores**, enquanto **2‚Åø** apenas dobra a cada passo.  
20. **T(n) = n¬≤ log n + 5n ‚Üí O(n¬≤ log n)** (termo dominante).

---
